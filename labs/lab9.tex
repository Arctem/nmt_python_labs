% LAB 9: Classes and Markov
% 
% CSE/IT 107: Introduction to Programming
% New Mexico Tech
% 
% Prepared by Russell White and Christopher Koch
% Fall 2014
\documentclass[11pt]{cselabheader}
\usepackage{caption}

%%%%%%%%%%%%%%%%%% SET TITLES %%%%%%%%%%%%%%%%%%%%%%%%%
\fancyhead[R]{Lab 9: Classes and Markov}
\title{Lab 9: Classes and Markov}

\begin{document}

\maketitle

\hrule
\begin{quotation}
``Simplicity is prerequisite for reliability.''
\end{quotation}
\begin{flushright}
--- Edsger W. Dijkstra
\end{flushright}

\begin{quotation}
``Simplicity is the final achievement. After one has played a vast quantity of
notes and more notes, it is simplicity that emerges as the crowning reward of
art.''
\end{quotation}
\begin{flushright}
--- Fr\`ed\`eric Chopin
\end{flushright}

\begin{quotation}
``Holy shit, you geeks are badass.''
\end{quotation}
\begin{flushright}
  --- Pam (\emph{Archer})
\end{flushright}

\begin{quotation}
``The truth is a trap: you can not get it without it getting you; you cannot get
the truth by capturing it, only by its capturing you.''
\end{quotation}
\begin{flushright}
--- S{\o}ren Kierkegaard
\end{flushright}

\begin{quotation}
  ``A police radar’s effective range is 1.0 km, and your roommate plot to drop water balloons on students entering your dorm. Your window is 20 m above the ground. (a) If an ammeter with 0.10-V resistance is 1000 V. When measured with a 100-Hz frequency shift, what’s the speed with which cesium atoms must be “tossed” in the positive x-direction with speed v0 but undergoing acceleration of a proton is a hydrogen atom?''
\end{quotation}
\begin{flushright}
  --- \href{http://infohost.nmt.edu/~rkelly/physbot.html}{Professor Markov's Physics Revue}
\end{flushright}

\hrule

\pagebreak
\section{Introduction}

This week's lab will be a small project using classes.

You will be
writing a program that generates
\href{http://en.wikipedia.org/wiki/Markov_chain}{Markov chains} from an input
file. Markov chains are the simplest way for to generate sentences that
imitate the style of the chain's input text.
They are based on figuring out the
likelihood of a word following another word by looking at existing bodies of
text (for example, Wikipedia). They then generate statements by choosing a
starting word and then repeatedly choosing words from the words that follow
the previous word chosen, based on the input text.

As an example, this was a markov chain generated based on conversations between
Russell and Chris about Python lab (given the starting word ``CS''):
\begin{quotation}
%``CS be hard!''
``CS grad student claiming to stare again for you? Cool! Where?''
\end{quotation}
\begin{flushright}
--- arcbot
\end{flushright}


\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{img/garkov}
  \caption*{\href{http://joshmillard.com/garkov/}{Garkov}:
    A Garfield comic generated using Markov chains.}
  \label{garkov}
\end{figure}

\pagebreak
\section{Classes}
\label{sec:classes}


\pagebreak
\section{Markov Chains}
\label{sec:markov}

A Markov chain is a method of randomly generating a sequence based on a set of
input data. In this lab, we will be using Markov chains to generate sentences
based on an input text file. In order to do this, we must understand how Markov
chains work.

The basic steps of creating Markov chains are:
\begin{enumerate}
  \item Select a random starting word to start our new sentence.
  \item From all the words that ever follow that word in the input sequence,
    choose one. Add that word to the end of our new sentence.
  \item Continue selecting randomly from the words that can possibly follow the
    current last word of our sentence until either there are no possible choices
    or we have made a sentence as long as desired.
\end{enumerate}

For a simple example, let's generate Markov phrases using inputs of ``Hello, how
are you?'' and ``Where are my keys?''. If we convert these sentences into a
graph showing the possible results, we would get Figure \ref{mark_ex}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.2\linewidth]{lab9/example}
  \caption{A graphical representation of the Markov possibilities for ``Hello,
    how are you?'' and ``Where are my keys?''}
  \label{mark_ex}
\end{figure}

In this graph, each arrow represents a choice we can take based on the last word
we added to our sentence, continuing until there are no valid paths to take.
Looking at the graph, it's pretty easy to see there are four possible outputs if
we start our chain with either ``Hello,'' or ``Where'':

\begin{itemize}
  \item Hello, how are you?
  \item Hello, how are my keys?
  \item Where are you?
  \item Where are my keys?
\end{itemize}

For a more complex example, let's use the input phrase ``There is a fifth
dimension, beyond that which is known to man. It is a dimension as vast as space
and as timeless as infinity.''. If we were to convert this sentence into a graph
representing the possible choices to make at each step, it would look something
like Figure \ref{twilight}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{lab9/twilight_zone}
  \caption{A graphical representation of the Markov possibilities for \emph{The
    Twilight Zone}'s introduction.}
  \label{twilight}
\end{figure}

In this graph, if we start with ``There'', our only option for a next word is
``is''. ``is'' is followed by ``a'' twice and ``known'' once, so it has two
arrows to ``a'' and one to ``known''. This means that, when we randomly choose a
next step, we should have a $\frac{2}{3}$ chance to choose ``a'' and a
$\frac{1}{3}$ chance to choose ``known''. If we (randomly) choose to continue to
``a'', we have the choice of either ``fifth'' or ``dimension'' to continue our
sentence with. A few possible new sentences we could generate from this input
are:
\begin{itemize}
  \item There is a dimension as infinity.
  \item There is a fifth dimension, beyond that which is a fifth dimension,
    beyond that which is a dimension as vast as space and as infinity.
  \item There is known to man. It is known to man. It is a dimension as space
    and as infinity.
\end{itemize}

As you can see, Markov chains have a tendency to make sentences which almost
make sense. This is because every individual pairing of two words will make
sense, but the combinations of the pairings might not. For example, ``as vast''
and ``vast as'' can both make sense given the right context, but ``vast as vast
as vast as vast'' is nonsense. We can help alleviate this problem by taking into
account the last 2 (or 3, or 4...) words when choosing the next word instead of
just the last one, but this requires a far larger input or it will result in the
output being the same as the input.

\subsection{Random Numbers}
\label{subsec:random}
You may find the module \lstinline!random! to be especially useful when
creating Markov chains. Below is a brief example of some common functions
inside \lstinline!random!.

\begin{lstlisting}[style=ipython]
>>> import random
>>> print(random.random())
0.7682548548225483
>>> print(random.uniform(1, 100))
36.30623079969581
>>> print(random.choice(['joe', 'moe', 'larry', 'shemp', 'curly']))
larry
>>> print(random.randint(1, 100))
79
\end{lstlisting}

Take a look at the documentation for \lstinline!random! if you would like a
random number not based on a uniform distribution:
\begin{center}
  \url{https://docs.python.org/3.4/library/random.html}
\end{center}

\begin{table}[!ht]
  \centering
  \begin{tabular}{p{3.0cm} p{2cm} p{10cm}}
    \toprule
    \bfseries Function & \bfseries Arguments & \bfseries Purpose \\
    \midrule
    \lstinline{random.random()} & & Returns a random number between 0.0 and 1.0,
    including 0.0 but not 1.0.\\
    \lstinline{random.uniform()} & \lstinline{a}, \lstinline{b} & Returns a
    random number between \lstinline{a} and \lstinline{b} inclusive. Each real number between
    \lstinline!a! and \lstinline!b! has an equal probability of occurring.\\
    \lstinline{random.randint()} & \lstinline{a}, \lstinline{b} & Returns a
    random integer between \lstinline{a} and \lstinline{b} inclusive. Each integer between
    \lstinline!a! and \lstinline!b! has an equal probability of occuring.\\
    \lstinline{random.choice()} & \lstinline{list} & Returns a random value from \lstinline{list}.\\
    \bottomrule
  \end{tabular}
  \caption{Summary of \lstinline{random} functions.}
  \label{tab:rand}
\end{table}

\clearpage
\section{Exercises}
\label{sec:ex}
\begin{description}
\item[markov.py] Write a class that works with the provided file
  \lstinline{markov_test.py} to generate markov chains based on provided
  input. \lstinline{markov_test.py} will import the code you write and
  use the class. You are not allowed to edit \lstinline{markov_test.py}
  for your submission, but you are free to comment out the sections
  that use parts of your code that have not been written yet while
  you write the lab.
  
  The expected contents of \lstinline{markov.py} are:
  
  \begin{description}
  \item[class Markov] A class that can be instantiated and used to
    generate markov chains.
    \begin{description}
    \item[def \_\_init\_\_(self)] Constructor for Markov that
      initializes any attributes you may need.
    \item[def add\_phrase(self, phrase)] Parse the string
      \lstinline!phrase! into the collected Markov data. The
      first word of \lstinline!phrase! should be considered a
      valid first word for generate\_phrase if none is specified.
    \item[def generate\_phrase(self, start=None)] Return a string
      generated using the Markov chain technique, based on all phrases
      previous added to this Markov instance. If start was specified,
      then the sentence should start with what was given. If not, the
      first word should be randomly chosen from all first words of all
      phrases added to the Markov instance. The chain should continue
      until either:
      \begin{itemize}
      \item There are no valid choices to continue the sentence with.
      \item The sentence has reached a length of 100 words.
      \end{itemize}
    \end{description}
  \end{description}
  
  You are free (and encouraged) to include any other functions that
  seem useful as you develop the class.
  
  As an example, the code
\begin{lstlisting}[style=ipython]
>>> import markov
>>> m = markov.Markov()
>>> m.add_phrase('Hello, how are you?')
>>> m.add_phrase('Where are my keys?')
>>> print(m.generate())
\end{lstlisting}
  might print either ``Hello, how are my keys?'' or ``Where are you?''.
  However, ``how are my keys?'' would not be valid, since ``how'' did
  not start either of the phrases added.

  Remember that you need to account for different frequencies of possible
  follow words. That is, a situation like in Figure \ref{twilight} where
  there is a higher chance for ``a'' to follow ``is'' than for ``known''
  to. You need to account for whatever probabilities might come up within
  the given phrases.

  \emph{Hint}: You may find dictionaries to be useful in implementing
  Markov chains.

\end{description}

\pagebreak
\section{Submitting}

Files to submit:
\begin{itemize}
\item markov.py (Section~\ref{sec:ex})
\end{itemize}

You may submit your code as either a tarball (instructions below) or as a .zip
file. Either one should contain all files used in the exercises for this lab.
The submitted file should be named either
\texttt{cse107\_firstname\_lastname\_lab9.zip} or
\texttt{cse107\_firstname\_lastname\_lab9.tar.gz} depending on which method you
used.

For Windows, use a tool you like to create a \texttt{.zip} file. The TCC
computers should have \texttt{7z} installed. For Linux, look at lab 1 for
instructions on how to create a tarball or use the ``Archive Manager'' graphical
tool.

\begin{center}
  \textbf{Upload your tarball or .zip file to Canvas.}
\end{center}

\end{document}
